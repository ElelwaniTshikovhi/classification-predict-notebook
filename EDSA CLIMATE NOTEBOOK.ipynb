{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f1e79f",
   "metadata": {},
   "source": [
    "# CLASSIFICATION Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**TEAM CBB3**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Predict Overview: EDSA - Climate Change Belief Analysis 2022\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "With this context, EDSA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n",
    "\n",
    "### Data overview\n",
    "Data The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected. Each tweet is labelled as one of the following classes:\n",
    "\n",
    "Class Description\n",
    "* 2 News: the tweet links to factual news about climate change\n",
    "* 1 Pro: the tweet supports the belief of man-made climate change\n",
    "* 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "* -1 Anti: the tweet does not believe in man-made climate change\n",
    "\n",
    "Variable definitions\n",
    "- sentiment: Sentiment of tweet\n",
    "- message: Tweet body\n",
    "- tweetid: Twitter unique id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9039e",
   "metadata": {},
   "source": [
    "# Team Supervisor\n",
    "- Chris Barnett\n",
    "\n",
    "# TEAM CBB3 MEMBERS\n",
    "- 1. Elelwani Tshikovhi (Team Leader);\n",
    "- 2. Katlego Maponya (Team coordinator) ;\n",
    "- 3. Musa Mashaba ;\n",
    "- 4. Zwothandwa Kunene ;\n",
    "- 5. Sinethemba Nongqoto;\n",
    "- 6. Desree Maleka\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f5c78",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Data Engineering</a>\n",
    "\n",
    "<a href=#four>4. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43532e06",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "|  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953959a",
   "metadata": {},
   "source": [
    "# Import all the  **libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da93645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "# Preprocessing\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "import time\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Modelling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Metrics for Model Evaluation\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikitplot.metrics import plot_roc, plot_confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Downloads\n",
    "#nltk.download('all')\n",
    "#nltk.download('stopwords')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928250b2",
   "metadata": {},
   "source": [
    "### Download NLTK Corpora\n",
    "Some of the `nltk` text processing methods introduced in this train involve a lookup operation. For example, to find all [stopwords](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) in a given string of text, we require a list of all possible stopwords in the English language to use for the lookup. Such a list is refered to as a [corpus](https://en.wikipedia.org/wiki/Text_corpus). Therefore, we need to first download the corpora we're going use, otherwise we may get a lookup error! Watch out specifically for the `tokenize` and `stopwords` sections. Not to worry, as we can easily avoid these errors by downloading the [corpora](http://www.nltk.org/nltk_data/) using the `nltk` downloader tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(['punkt','stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "print(stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b795a",
   "metadata": {},
   "source": [
    "pip intall comet version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import comet_ml at the top \n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"rI7gAvhuv8lNvQcjSox3TjwIF\",\n",
    "    project_name=\"team-cbb-3-classification\",\n",
    "    workspace=\"elelwani-tshikovhi\",\n",
    ")\n",
    "\n",
    "# Run your code and go to /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed149e03",
   "metadata": {},
   "source": [
    "*   [Trello Link](https://trello.com/b/2KvEPRJi/advanced-classificatin-team-cbb3-week-1)\n",
    "*   [Link to comet](https://www.comet.ml/elelwani-tshikovhi/team-cbb-3-classification/view/new/panels)\n",
    "*   [Link to Github](https://github.com/TEAMCBB3Classificationpredict)\n",
    "*   [Link to streamlit]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c5843",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fdb9a3",
   "metadata": {},
   "source": [
    "The training and testing data, trains_set and test_set respectively are loaded as Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/TEAMCBB3Classificationpredict/datasets/main/train.csv')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/TEAMCBB3Classificationpredict/datasets/main/test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2282b667",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 3. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "|  clean the dataset, and possibly create new features - as identified in the EDA phase. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6cf79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ca522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2114d0d1",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 4. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "|This phase is important. This will help to understand patterns in the data, pinpoint any outliers and indicate relationships between variables uusing  descriptive statistics and data visualisations\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7a46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d5dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17c86bf4",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, create one or more regression models that are able to accurately predict the three hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9152f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8547bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81af3878",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680bede2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0cf1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9274a336",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa1075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
